{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes = ['Day', 'Outlook', 'Temparature', 'Humidity', 'Wind']\n",
      "[['Day', 'Outlook', 'Temperature', 'Humidity', 'Wind', 'Play?'], ['D1', 'Sunny', 'Hot', 'High', 'Weak', 'No'], ['D2', 'Sunny', 'Hot', 'High', 'Strong', 'No'], ['D3', 'Overcast', 'Hot', 'High', 'Weak', 'Yes'], ['D4', 'Rain', 'Mild', 'High', 'Weak', 'Yes'], ['D5', 'Rain', 'Cool', 'Normal', 'Weak', 'Yes'], ['D6', 'Rain', 'Cool', 'Normal', 'Strong', 'No'], ['D7', 'Overcast', 'Cool', 'Normal', 'Strong', 'Yes'], ['D8', 'Sunny', 'Mild', 'High', 'Weak', 'No'], ['D9', 'Sunny', 'Cool', 'Normal', 'Weak', 'Yes'], ['D10', 'Rain', 'Mild', 'Normal', 'Weak', 'Yes'], ['D11', 'Sunny', 'Mild', 'Normal', 'Strong', 'Yes'], ['D12', 'Overcast', 'Mild', 'High', 'Strong', 'Yes'], ['D13', 'Overcast', 'Hot', 'Normal', 'Weak', 'Yes'], ['D14', 'Rain', 'Mild', 'High', 'Strong', 'No']]\n",
      "Intial Hypothesis\n",
      "['0', '0', '0', '0', '0']\n",
      "The Hypothesis are\n",
      "5 = ['?', 'Overcast', 'Hot', 'High', 'Weak']\n",
      "Final Hypothesis\n",
      "['?', 'Overcast', 'Hot', 'High', 'Weak']\n",
      "5 = ['?', '?', 'Hot', 'High', 'Weak']\n",
      "Final Hypothesis\n",
      "['?', '?', 'Hot', 'High', 'Weak']\n",
      "5 = ['?', '?', '?', 'High', 'Weak']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', 'High', 'Weak']\n",
      "6 = ['?', '?', '?', 'High', 'Weak']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', 'High', 'Weak']\n",
      "6 = ['?', '?', '?', 'High', 'Weak']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', 'High', 'Weak']\n",
      "6 = ['?', '?', '?', 'High', 'Weak']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', 'High', 'Weak']\n",
      "6 = ['?', '?', '?', '?', 'Weak']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', 'Weak']\n",
      "8 = ['?', '?', '?', '?', 'Weak']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', 'Weak']\n",
      "8 = ['?', '?', '?', '?', 'Weak']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', 'Weak']\n",
      "8 = ['?', '?', '?', '?', 'Weak']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', 'Weak']\n",
      "8 = ['?', '?', '?', '?', 'Weak']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', 'Weak']\n",
      "8 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "10 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "10 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "10 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "10 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "10 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "11 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "11 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "11 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "11 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "11 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "12 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "12 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "12 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "12 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "12 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "13 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "13 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "13 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "13 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "13 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "14 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "14 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "14 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "14 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n",
      "14 = ['?', '?', '?', '?', '?']\n",
      "Final Hypothesis\n",
      "['?', '?', '?', '?', '?']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"r\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = dataset[i]\n",
    "        return dataset\n",
    "    \n",
    "attributes = ['Day','Outlook','Temparature','Humidity','Wind']\n",
    "print('Attributes =',attributes)\n",
    "num_attributes = len(attributes)\n",
    "filename = \"dataset.csv\"\n",
    "dataset = loadCsv(filename)\n",
    "print(dataset)\n",
    "hypothesis=['0'] * num_attributes\n",
    "print(\"Intial Hypothesis\")\n",
    "print(hypothesis)\n",
    "print(\"The Hypothesis are\")\n",
    "for i in range(len(dataset)):\n",
    "    target = dataset[i][-1]\n",
    "    \n",
    "    if(target == 'Yes'):\n",
    "        \n",
    "        for j in range(num_attributes):\n",
    "            if(hypothesis[j]=='0'): \n",
    "                hypothesis[j] = dataset[i][j]\n",
    "            if(hypothesis[j]!= dataset[i][j]):\n",
    "                hypothesis[j]='?'\n",
    "                print(i+1,'=',hypothesis)\n",
    "                print(\"Final Hypothesis\")\n",
    "                print(hypothesis)\n",
    "                \n",
    "                         \n",
    "                    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin : Hypothesis : ['phi', 'phi', 'phi', 'phi', 'phi', 'phi']\n",
      "==========================================\n",
      "Number of attributes are not same in hypothesis.\n",
      "Training data         : ['D3', 'Overcast', 'Hot', 'High', 'Weak', 'Yes']\n",
      "Updated Hypothesis    : ['D3', 'Overcast', 'Hot', 'High', 'Weak', 'Yes']\n",
      "\n",
      "--------------------------------\n",
      "==========================================\n",
      "maximally sepcific data set End: Hypothesis : ['D3', 'Overcast', 'Hot', 'High', 'Weak', 'Yes']\n",
      "Number of attributes are not same in hypothesis.\n",
      "Training data         : ['D4', 'Rain', 'Mild', 'High', 'Weak', 'Yes']\n",
      "Updated Hypothesis    : ['any', 'any', 'any', 'High', 'Weak', 'Yes']\n",
      "\n",
      "--------------------------------\n",
      "==========================================\n",
      "maximally sepcific data set End: Hypothesis : ['any', 'any', 'any', 'High', 'Weak', 'Yes']\n",
      "Number of attributes are not same in hypothesis.\n",
      "Training data         : ['D5', 'Rain', 'Cool', 'Normal', 'Weak', 'Yes']\n",
      "Updated Hypothesis    : ['any', 'any', 'any', 'any', 'Weak', 'Yes']\n",
      "\n",
      "--------------------------------\n",
      "==========================================\n",
      "maximally sepcific data set End: Hypothesis : ['any', 'any', 'any', 'any', 'Weak', 'Yes']\n",
      "Number of attributes are not same in hypothesis.\n",
      "Training data         : ['D7', 'Overcast', 'Cool', 'Normal', 'Strong', 'Yes']\n",
      "Updated Hypothesis    : ['any', 'any', 'any', 'any', 'any', 'Yes']\n",
      "\n",
      "--------------------------------\n",
      "==========================================\n",
      "maximally sepcific data set End: Hypothesis : ['any', 'any', 'any', 'any', 'any', 'Yes']\n",
      "Number of attributes are not same in hypothesis.\n",
      "Training data         : ['D9', 'Sunny', 'Cool', 'Normal', 'Weak', 'Yes']\n",
      "Updated Hypothesis    : ['any', 'any', 'any', 'any', 'any', 'Yes']\n",
      "\n",
      "--------------------------------\n",
      "==========================================\n",
      "maximally sepcific data set End: Hypothesis : ['any', 'any', 'any', 'any', 'any', 'Yes']\n",
      "Number of attributes are not same in hypothesis.\n",
      "Training data         : ['D10', 'Rain', 'Mild', 'Normal', 'Weak', 'Yes']\n",
      "Updated Hypothesis    : ['any', 'any', 'any', 'any', 'any', 'Yes']\n",
      "\n",
      "--------------------------------\n",
      "==========================================\n",
      "maximally sepcific data set End: Hypothesis : ['any', 'any', 'any', 'any', 'any', 'Yes']\n",
      "Number of attributes are not same in hypothesis.\n",
      "Training data         : ['D11', 'Sunny', 'Mild', 'Normal', 'Strong', 'Yes']\n",
      "Updated Hypothesis    : ['any', 'any', 'any', 'any', 'any', 'Yes']\n",
      "\n",
      "--------------------------------\n",
      "==========================================\n",
      "maximally sepcific data set End: Hypothesis : ['any', 'any', 'any', 'any', 'any', 'Yes']\n",
      "Number of attributes are not same in hypothesis.\n",
      "Training data         : ['D12', 'Overcast', 'Mild', 'High', 'Strong', 'Yes']\n",
      "Updated Hypothesis    : ['any', 'any', 'any', 'any', 'any', 'Yes']\n",
      "\n",
      "--------------------------------\n",
      "==========================================\n",
      "maximally sepcific data set End: Hypothesis : ['any', 'any', 'any', 'any', 'any', 'Yes']\n",
      "Number of attributes are not same in hypothesis.\n",
      "Training data         : ['D13', 'Overcast', 'Hot', 'Normal', 'Weak', 'Yes']\n",
      "Updated Hypothesis    : ['any', 'any', 'any', 'any', 'any', 'Yes']\n",
      "\n",
      "--------------------------------\n",
      "==========================================\n",
      "maximally sepcific data set End: Hypothesis : ['any', 'any', 'any', 'any', 'any', 'Yes']\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        datareader = csv.reader(csvfile, delimiter=',')         \n",
    "        traindata = []\n",
    "        for row in datareader:\n",
    "            traindata.append(row)\n",
    "    return (traindata)\n",
    "           \n",
    "h=['phi','phi','phi','phi','phi','phi'] \n",
    "data=read_data('dataset.csv') \n",
    "def isConsistent(h,d):\n",
    "    if len(h)!=len(d)-1:\n",
    "        print('Number of attributes are not same in hypothesis.')\n",
    "        return False \n",
    "    else:\n",
    "            matched=0\n",
    "            for i in range(len(h)):\n",
    "                if ( (h[i]==d[i]) | (h[i]=='any') ):\n",
    "                    matched=matched+1\n",
    "                if matched==len(h):\n",
    "                    return True\n",
    "                else:\n",
    "                    return False \n",
    "def makeConsistent(h,d):   \n",
    "    for i in range(len(h)):           \n",
    "        if((h[i] == 'phi')):                \n",
    "            h[i]=d[i]           \n",
    "        elif(h[i]!=d[i]):                \n",
    "            h[i]='any'      \n",
    "    return h\n",
    "\n",
    "print('Begin : Hypothesis :',h) \n",
    "print('==========================================') \n",
    "for d in data:         \n",
    "    if d[len(d)-1]=='Yes':                 \n",
    "        if ( isConsistent(h,d)):                  \n",
    "            pass          \n",
    "        else:               \n",
    "                   h=makeConsistent(h,d)         \n",
    "        print ('Training data         :',d)         \n",
    "        print ('Updated Hypothesis    :',h)         \n",
    "        print()         \n",
    "        print('--------------------------------') \n",
    "        print('==========================================') \n",
    "        print('maximally sepcific data set End: Hypothesis :',h) \n",
    " \n",
    "               \n",
    "               \n",
    "               \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    " \n",
    "data = pd.DataFrame(data=pd.read_csv('dataset.csv')) \n",
    "concepts = np.array(data.iloc[:,0:-1]) \n",
    " \n",
    "target = np.array(data.iloc[:,-1]) \n",
    "def learn(concepts, target):     \n",
    "    specific_h = concepts[0].copy()     \n",
    "    print(\"initialization of specific_h and general_h\")     \n",
    "    print(specific_h)     \n",
    "    general_h = [[\"?\" for i in range(len(specific_h))] for i in range(len(specific_h))]     \n",
    "    print(general_h)     \n",
    "    for i, h in enumerate(concepts):         \n",
    "        if target[i] == \"Yes\":             \n",
    "            for x in range(len(specific_h)):                 \n",
    "                if h[x] != specific_h[x]:                     \n",
    "                    specific_h[x] = '?'\n",
    "                    general_h[x][x] = '?'\n",
    "                        \n",
    "                if target[i] == \"No\":             \n",
    "                    for x in range(len(specific_h)):                 \n",
    "                        if h[x] != specific_h[x]:                     \n",
    "                            general_h[x][x] = specific_h[x]                 \n",
    "                        else:                     \n",
    "                            general_h[x][x] = '?'     \n",
    "        print(\" steps of Candidate Elimination Algorithm\",i+1)     \n",
    "        print(\"Specific_h \",i+1,\"\\n \")     \n",
    "        print(specific_h)     \n",
    "        print(\"general_h \", i+1, \"\\n \")     \n",
    "        print(general_h)   \n",
    "        \n",
    "        indices = [i for i, val in enumerate(general_h) if val == ['?', '?', '?', '?', '?', '?']]     \n",
    "        for i in indices:             \n",
    "                general_h.remove(['?', '?', '?', '?', '?', '?'])          \n",
    "                return specific_h, general_h \n",
    "s_final, g_final = learn(concepts, target)\n",
    "print(\"Final Specific_h:\", s_final, sep=\"\\n\") \n",
    "print(\"Final General_h:\", g_final, sep=\"\\n\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization of specific_h and general_h\n",
      "['Japan' 'Honda' 'Blue' 1980 'Economy']\n",
      "[['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n",
      " steps of Candidate Elimination Algorithm 1\n",
      "Specific_h  1 \n",
      " \n",
      "['Japan' 'Honda' 'Blue' 1980 'Economy']\n",
      "general_h  1 \n",
      " \n",
      "[['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n",
      " steps of Candidate Elimination Algorithm 2\n",
      "Specific_h  2 \n",
      " \n",
      "['Japan' 'Honda' 'Blue' 1980 'Economy']\n",
      "general_h  2 \n",
      " \n",
      "[['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n",
      " steps of Candidate Elimination Algorithm 3\n",
      "Specific_h  3 \n",
      " \n",
      "['Japan' 'Honda' 'Blue' 1980 'Economy']\n",
      "general_h  3 \n",
      " \n",
      "[['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n",
      " steps of Candidate Elimination Algorithm 4\n",
      "Specific_h  4 \n",
      " \n",
      "['Japan' 'Honda' 'Blue' 1980 'Economy']\n",
      "general_h  4 \n",
      " \n",
      "[['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n",
      " steps of Candidate Elimination Algorithm 5\n",
      "Specific_h  5 \n",
      " \n",
      "['Japan' 'Honda' 'Blue' 1980 'Economy']\n",
      "general_h  5 \n",
      " \n",
      "[['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n",
      " steps of Candidate Elimination Algorithm 6\n",
      "Specific_h  6 \n",
      " \n",
      "['Japan' 'Honda' 'Blue' 1980 'Economy']\n",
      "general_h  6 \n",
      " \n",
      "[['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n",
      " steps of Candidate Elimination Algorithm 7\n",
      "Specific_h  7 \n",
      " \n",
      "['Japan' 'Honda' 'Blue' 1980 'Economy']\n",
      "general_h  7 \n",
      " \n",
      "[['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-3762051b6ba8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mgeneral_h\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'?'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'?'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'?'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'?'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'?'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'?'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mspecific_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneral_h\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0ms_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcepts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Final Specific_h:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Final General_h:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "#CEA JAPAN dataset\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    " \n",
    "data = pd.DataFrame(data=pd.read_csv('dataset2.csv')) \n",
    "concepts = np.array(data.iloc[:,0:-1]) \n",
    " \n",
    "target = np.array(data.iloc[:,-1]) \n",
    "def learn(concepts, target):     \n",
    "    specific_h = concepts[0].copy()     \n",
    "    print(\"initialization of specific_h and general_h\")     \n",
    "    print(specific_h)     \n",
    "    general_h = [[\"?\" for i in range(len(specific_h))] for i in range(len(specific_h))]     \n",
    "    print(general_h)     \n",
    "    for i, h in enumerate(concepts):         \n",
    "        if target[i] == \"Yes\":             \n",
    "            for x in range(len(specific_h)):                 \n",
    "                if h[x] != specific_h[x]:                     \n",
    "                    specific_h[x] = '?'\n",
    "                    general_h[x][x] = '?'\n",
    "                        \n",
    "                if target[i] == \"No\":             \n",
    "                    for x in range(len(specific_h)):                 \n",
    "                        if h[x] != specific_h[x]:                     \n",
    "                            general_h[x][x] = specific_h[x]                 \n",
    "                        else:                     \n",
    "                            general_h[x][x] = '?'     \n",
    "        print(\" steps of Candidate Elimination Algorithm\",i+1)     \n",
    "        print(\"Specific_h \",i+1,\"\\n \")     \n",
    "        print(specific_h)     \n",
    "        print(\"general_h \", i+1, \"\\n \")     \n",
    "        print(general_h)   \n",
    "        \n",
    "        indices = [i for i, val in enumerate(general_h) if val == ['?', '?', '?', '?', '?', '?']]     \n",
    "        for i in indices:             \n",
    "                general_h.remove(['?', '?', '?', '?', '?', '?'])          \n",
    "                return specific_h, general_h \n",
    "s_final, g_final = learn(concepts, target)\n",
    "print(\"Final Specific_h:\", s_final, sep=\"\\n\") \n",
    "print(\"Final General_h:\", g_final, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
